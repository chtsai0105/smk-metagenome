import os
import pandas as pd
import re


class df_prebuild(object):
    def __init__(self, df):
        df = df.copy()
        self.__check(df)
        df = self.__interleave_paired_samples(df)
        self.df = df

    def __check(self, df):
        for idx, v in df.iterrows():
            if bool(v['R1']) ^ bool(v['R2']):
                raise ValueError("One of the paired-end reads is missing (R1 or R2).")
            if not bool(v['R1']) ^ bool(v['interleaved']):
                raise ValueError("R1/R2 and interleaved should be mutually exclusive.")

    def __interleave_paired_samples(self, df):
        paired_idx = df.query('interleaved == ""').index
        df.loc[paired_idx, 'interleaved'] = df.loc[paired_idx, 'sample'] + '_interleaved.fastq.gz'
        return df

    def samples(self):
        return self.df['sample'].drop_duplicates().tolist()

    def filepath_generator(self, sample, path="", column='interleaved'):
        return [os.path.join(path, x) for x in self.df.query('sample == @sample')[column].tolist()]

    
############### Configuration ##############
configfile: "config/config.yaml"
data = pd.read_csv(config['Metadata'], keep_default_na=False, na_values=['_'], comment="#")
data = df_prebuild(data)

FASTQ = config['raw_data']['fastq']
FASTQC_OUTPUT = config['fastqc']['output']
KRAKEN2_OUTPUT = config['kraken2']['output']
MMSEQS2_OUTPUT = config['mmseqs2']['output']
ASSEMBLY_OUTPUT = config['assembly']['output']
FILTERED_CONTIGS = config['assembly']['filtered_contigs']
MAPPING_OUTPUT = config['align_to_assembly']['output']
AUTOMETA_OUTPUT = config['autometa']['output']
METABAT_OUTPUT = config['metabat']['output']
GTDBTK_OUTPUT = config['gtdbtk']['output']
FUNC_ANNO_OUTPUT = config['functional_annotation']['output']
############### Input settings #############
input_list = list()

### preprocessed reads
include: "rules/preprocess.smk"
input_list.extend(["{dir}/preprocess_done/{sample}_R1.fastq.gz".format(dir=FASTQ, sample=sample) for sample in data.samples()])
input_list.extend(["{dir}/preprocess_done/{sample}_R2.fastq.gz".format(dir=FASTQ, sample=sample) for sample in data.samples()])

### FastQC
if config['fastqc']['run']:
    input_list.extend(["{dir}/pre_trim/{sample}_fastqc.html".format(dir=FASTQC_OUTPUT, sample=sample) for sample in data.samples()])
    input_list.extend(["{dir}/pre_trim/{sample}_fastqc.zip".format(dir=FASTQC_OUTPUT, sample=sample) for sample in data.samples()])

### Trimmomatic and post-trim fastqc
if config['trimming']['run']:
    input_list.extend(["{dir}/trimmed/{sample}.fastq.gz".format(dir=FASTQ, sample=sample) for sample in data.samples()])
    input_list.extend(["{dir}/trimmed/{sample}.fastq.gz".format(dir=FASTQ, sample=sample) for sample in data.samples()])
    if config['fastqc']['run']:
        input_list.extend(["{dir}/post_trim/{sample}_fastqc.html".format(dir=FASTQC_OUTPUT, sample=sample) for sample in data.samples()])
        input_list.extend(["{dir}/post_trim/{sample}_fastqc.zip".format(dir=FASTQC_OUTPUT, sample=sample) for sample in data.samples()])

### Kraken2
if config['kraken2']['run']:
    include: "rules/kraken2.smk"
    input_list.extend(["{dir}/{sample}_taxon.csv".format(dir=KRAKEN2_OUTPUT, sample=sample) for sample in data.samples()])

### mmseqs2
if config['mmseqs2']['run']:
    include: "rules/mmseqs2.smk"
    input_list.extend(["{dir}/{sample}".format(dir=MMSEQS2_OUTPUT, sample=sample) for sample in data.samples()])

### Assembly
if config['assembly']['run']:
    include: "rules/assembly.smk"
    input_list.extend(["{dir}/{sample}_contigs.fasta".format(dir=FILTERED_CONTIGS, sample=sample) for sample in data.samples()])
    input_list.extend(["{dir}/{sample}_filtered.fasta".format(dir=FILTERED_CONTIGS, sample=sample) for sample in data.samples()])  # filtered_fasta

### Post-assembly alignment
if config['align_to_assembly']['run']:
    include: "rules/post_checkup.smk"
    if config['align_to_assembly']['tools'] == "bbmap":
        input_list.extend(["{dir}/{sample}_refstats.tsv".format(dir=MAPPING_OUTPUT, sample=sample) for sample in data.samples()])
    else:
        input_list.extend(["{dir}/{sample}.stats".format(dir=MAPPING_OUTPUT, sample=sample) for sample in data.samples()])

### autometa.smk
if config['autometa']['run']:
    include: "rules/autometa.smk"

    input_list.extend(["{dir}/{sample}/intermediates/coverage.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample) for sample in data.samples()])  # cov_tab
    input_list.extend(["{dir}/{sample}/intermediates/blastp.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample) for sample in data.samples()])    # blastp
    input_list.extend(["{dir}/{sample}/intermediates/taxonomy/taxonomy.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample) for sample in data.samples()])   # taxonomy
    
    for kingdom in config['autometa']['binning_target']:
        # input_list.extend(["{dir}/{sample}/intermediates/{kingdom}.markers.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()])  # autometa_markers
        # input_list.extend(["{dir}/{sample}/{kingdom}_binning.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()])  # binning_output
        # input_list.extend(["{dir}/{sample}/{kingdom}_main.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()]) # main_output
        if config['autometa']['unclustered_recruitment']:
            input_list.extend(["{dir}/{sample}/{kingdom}_recruitment_binning.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()])    # metabin_stats
            input_list.extend(["{dir}/{sample}/{kingdom}_recruitment_features.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()]) # metabin_taxonomy
            input_list.extend(["{dir}/{sample}/{kingdom}_recruitment_main.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()]) # metabin
        input_list.extend(["{dir}/{sample}/{kingdom}_metabin_stats.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()])    # metabin_stats
        input_list.extend(["{dir}/{sample}/{kingdom}_metabin_taxonomy.tsv".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()]) # metabin_taxonomy
        input_list.extend(["{dir}/{sample}/{kingdom}_metabins".format(dir=AUTOMETA_OUTPUT, sample=sample, kingdom=kingdom) for sample in data.samples()]) # metabin

if config['metabat']['run']:
    include: "rules/metabat.smk"
    input_list.extend(["{dir}/{sample}/bin".format(dir=METABAT_OUTPUT, sample=sample) for sample in data.samples()])

if config['gtdbtk']['run']:
    include: "rules/gtdbtk.smk"
    input_list.extend(["{dir}/{sample}".format(dir=GTDBTK_OUTPUT, sample=sample) for sample in data.samples()])

if config['functional_annotation']['run']:
    include: "rules/functional_annotation.smk"
    if config['functional_annotation']['clustering']:
        input_list.extend(["{dir}/intermediate/{sample}_alignment_readcounts.csv".format(dir=FUNC_ANNO_OUTPUT, sample=sample) for sample in data.samples()])
    if "dbcan" in config['functional_annotation']['tools']:
        input_list.extend(["{dir}/dbcan/{sample}/overview.txt".format(dir=FUNC_ANNO_OUTPUT, sample=sample) for sample in data.samples()])
    if "kofamscan" in config['functional_annotation']['tools']:
        input_list.extend(["{dir}/kofamscan/{sample}.txt".format(dir=FUNC_ANNO_OUTPUT, sample=sample) for sample in data.samples()])



############### Rules ######################
rule all:
    input:
        input_list
